---
id: BonusValidator
name: Bonus Validator
type: skill
version: 1.0.0
category: quality-assurance
tags: [validation, hackathon, bonus, checklist]
---

# BonusValidator Skill

## Purpose
Validates whether implemented features and workflows meet hackathon bonus point criteria. Provides clear yes/no answers with detailed explanations, ensuring the project maximizes reusable intelligence, personalization, Urdu translation, and Spec-Kit Plus artifacts.

## Inputs

```yaml
feature_description:
  type: string
  description: "Description of the feature or implementation to validate (e.g., 'chapter writer skill for auto-generating MDX', 'per-chapter Urdu toggle button', 'user background collection form')"
  required: true

feature_category:
  type: string
  enum: [skill, component, workflow, content, auth, translation, artifact]
  description: "Category of feature being validated"
  required: true

implementation_details:
  type: object
  description: "Implementation specifics for detailed validation"
  properties:
    technology_stack: array<string>
    reusability_score: integer (0-10)
    documentation_level: string (enum: minimal, partial, comprehensive)
    testing_coverage: string (enum: untested, unit-only, integration, end-to-end)
    user_feedback: string
  required: false
```

## Output

Structured validation report:

```json
{
  "feature_name": "ChapterWriter Agent Skill",
  "category": "skill",
  "is_bonus_qualifying": true,
  "bonus_criteria_met": [
    {
      "criterion": "Reusable Intelligence (Claude Code Subagents & Skills)",
      "status": "✅ PASS",
      "explanation": "ChapterWriter skill is a standalone Claude Code agent skill that generates production-ready MDX chapters. It's reusable across all 12 chapters in the project, reduces manual content work by 60%, and can be adapted for similar educational projects.",
      "confidence": "high"
    },
    {
      "criterion": "Bonus Multiplier: Automation & Intelligence",
      "status": "✅ PASS",
      "explanation": "Automates chapter creation workflow, reduces content writing time by significant margin, applies AI to educational content production.",
      "confidence": "high"
    }
  ],
  "bonus_criteria_not_met": [],
  "bonus_points_estimate": {
    "reusable_intelligence": 10,  // out of 10
    "implementation_quality": 9,
    "documentation_quality": 10,
    "total_bonus_multiplier": 2.0  // up to 2x project score
  },
  "recommendations": [
    "Ensure skill is well-documented in .claude/skills/ChapterWriter.claude_skill",
    "Include usage examples in skill file",
    "Test skill with 2-3 real chapters before submission"
  ],
  "detailed_reasoning": "This skill embodies bonus criteria: it's a reusable Claude Code agent skill that demonstrates advanced AI orchestration. The skill generator reduces manual content production and can be reused across similar projects, maximizing the 'reusable intelligence' bonus multiplier."
}
```

## Bonus Criteria Reference

### ⭐ Reusable Intelligence (via Claude Code Subagents & Skills)

**Definition**: Create standalone, reusable Claude Code agents/skills that can be applied across the project and beyond.

**Bonus-Qualifying Features**:
- ✅ Agent Skills (`.claude/skills/*.claude_skill`) that solve general problems (chapter writing, translation, personalization, code generation, diagram creation, validation)
- ✅ Subagent workflows that delegate tasks (@Educator, @FrontendEngineer, @BackendEngineer, @Translator, @Reviewer)
- ✅ Agent composition: using multiple agents in parallel to accelerate development
- ✅ Reusability: skill can be used in different chapters, different projects, different contexts
- ✅ Documentation: skills are well-documented with inputs, outputs, usage examples
- ✅ Extensibility: skill can be adapted or extended without core changes

**Scoring**:
- 1-2 simple skills: 1x multiplier
- 3-4 well-documented skills: 1.3x multiplier
- 5-7 sophisticated skills with examples: 1.7x multiplier
- 7+ skills with extensive automation & orchestration: **2.0x multiplier**

**Validation Checklist**:
- [ ] Skill is in `.claude/skills/` directory
- [ ] Skill has clear purpose, inputs, outputs
- [ ] Skill is used in actual project workflow (not hypothetical)
- [ ] Skill reduces manual work by >20%
- [ ] Skill is documented with examples
- [ ] Skill can be reused (not tied to specific chapter/feature)

### ⭐ Prompt History Records (PHRs) & Architecture Decision Records (ADRs)

**Definition**: Create and maintain PHRs and ADRs as first-class project artifacts.

**Bonus-Qualifying Features**:
- ✅ PHR created for every major phase (spec, planning, implementation, testing, deployment)
- ✅ PHRs stored in `history/prompts/` with proper routing (constitution, feature, general)
- ✅ ADRs created for significant architectural decisions (>3 decisions recommended)
- ✅ ADRs document context, alternatives, rationale, consequences
- ✅ PHRs and ADRs are treated as living documentation, not throwaway

**Scoring**:
- 1-2 PHRs: minimal bonus
- 5-8 comprehensive PHRs: 1.3x multiplier
- 10+ PHRs with proper routing + 3-5 ADRs: **1.5x multiplier** (multiplicative with skills)

**Validation Checklist**:
- [ ] PHR files exist in `history/prompts/` with correct naming
- [ ] PHRs contain full context, prompts, responses
- [ ] At least 3 ADRs document major decisions
- [ ] ADRs reference alternatives and tradeoffs
- [ ] PHRs/ADRs are integrated into development workflow (not added at end)

### ⭐ User Personalization & Authentication

**Definition**: Implement production-ready user authentication and content adaptation based on user profile.

**Bonus-Qualifying Features**:
- ✅ Better-Auth integration: signup, signin, logout with email verification
- ✅ User background collection: software level, hardware level, learning goal
- ✅ Content adaptation: chapter content adapts based on user profile
- ✅ Difficulty toggle: per-chapter button to switch basic ↔ advanced
- ✅ Progress tracking: save bookmarks, quiz scores, time spent per chapter
- ✅ Preference persistence: user settings saved to database
- ✅ Multi-user testing: validated with 3+ user personas

**Scoring**:
- Auth only (no personalization): minimal bonus
- Auth + basic personalization (1 feature): 1.2x multiplier
- Auth + 3+ personalization features (difficulty, bookmarks, progress): **1.4x multiplier**
- Auth + 5+ features (all above + recommendations, learning paths, analytics): **1.6x multiplier**

**Validation Checklist**:
- [ ] Better-Auth is integrated and tested
- [ ] User background form collects software/hardware/goal
- [ ] Content adaptation is functional (not just UI buttons)
- [ ] Difficulty toggle changes chapter content
- [ ] Progress tracking saves to database
- [ ] 3+ user personas tested end-to-end
- [ ] Personalization logic is documented

### ⭐ Urdu Language Translation

**Definition**: Provide production-ready Urdu translation of course content while preserving technical terms and code.

**Bonus-Qualifying Features**:
- ✅ At least 50% of chapters translated to high-quality Urdu
- ✅ Technical terms preserved in English (ROS 2, URDF, Gazebo, VLA, etc.)
- ✅ Code blocks unchanged (Python/C++ code not translated)
- ✅ MDX syntax preserved (all components, links, formatting intact)
- ✅ Per-chapter Urdu toggle button functional
- ✅ Translation reviewed by native Urdu speaker
- ✅ Glossary of technical terms provided

**Scoring**:
- 25-50% chapters translated (basic): 1.1x multiplier
- 50-75% chapters translated with review: 1.3x multiplier
- 75%+ chapters translated, reviewed, with glossary: **1.5x multiplier**
- 100% chapters translated + dual-language features (search, glossary, recommendations): **1.7x multiplier**

**Validation Checklist**:
- [ ] Minimum 50% of chapters have Urdu version
- [ ] Technical terms (ROS 2, URDF, etc.) stay in English
- [ ] Code blocks are identical in both versions
- [ ] Urdu toggle button works on chapter pages
- [ ] Urdu text is grammatically correct (native speaker verified)
- [ ] MDX syntax is valid in Urdu version
- [ ] Glossary maps English technical terms to Urdu

### ⭐ Comprehensive Spec-Kit Plus Artifacts

**Definition**: Follow Spec-Kit Plus workflow rigorously and produce all artifacts as deliverables.

**Bonus-Qualifying Features**:
- ✅ Constitution: project principles documented and ratified
- ✅ Specification: detailed spec with all sections (scope, architecture, APIs, testing, risks)
- ✅ Clarification: specific questions asked and answered before planning
- ✅ Plan: implementation phases, subagent assignments, dependencies
- ✅ Tasks: atomic, testable tasks with acceptance criteria
- ✅ Analysis: cross-artifact consistency check (spec ↔ plan ↔ tasks alignment)
- ✅ Implementation: code written against tasks, traced to spec
- ✅ ADRs: major decisions documented
- ✅ PHRs: all phases recorded with full context

**Scoring**:
- Constitution + Spec only: minimal bonus
- Constitution + Spec + Plan + Tasks: 1.2x multiplier
- All above + PHRs for each phase: 1.3x multiplier
- Complete SDD workflow + 5+ ADRs: **1.5x multiplier**

**Validation Checklist**:
- [ ] Constitution.md exists and is ratified
- [ ] Spec.md has 8+ sections covering full project
- [ ] Clarification phase documented (questions answered)
- [ ] Plan.md details phases, subagents, dependencies
- [ ] Tasks.md breaks spec into atomic items
- [ ] Analysis report compares artifacts for consistency
- [ ] Implementation code references spec/plan/tasks
- [ ] 5+ ADRs document architectural decisions
- [ ] 8+ PHRs in history/prompts/ with proper routing

---

## Validation Procedures

### 1. Reusable Intelligence Validation

```
Feature: ChapterWriter Skill
Is it reusable? Can it be used for chapters beyond this project? YES
Has it reduced manual work? Can measure by comparing: auto-gen time vs. manual time YES
Is it well-documented? Check .claude/skills/ChapterWriter.claude_skill for clarity YES
Can others use it? Provide usage examples, input/output specs YES
→ BONUS QUALIFYING ✅
```

### 2. Personalization Validation

```
Feature: Difficulty Toggle Button
Can user click button on chapter page? YES (UI implemented)
Does content change when clicked? YES (different explanations shown)
Is change saved to database? YES (user_preferences table)
Does it work for multiple users? YES (tested with 3+ personas)
Is it in production (not stub)? YES (full implementation)
→ BONUS QUALIFYING ✅
```

### 3. Urdu Translation Validation

```
Feature: Module 2 (Gazebo/Unity) Urdu Translation
Is 50%+ of chapter translated? YES (all 5 chapters)
Are technical terms in English? YES (Gazebo, URDF, Physics, etc.)
Are code blocks unchanged? YES (Python code identical)
Is MDX syntax valid? YES (all components work)
Was it reviewed by native speaker? YES (review feedback attached)
→ BONUS QUALIFYING ✅
```

### 4. Spec-Kit Plus Artifacts Validation

```
Constitution: ✅ (ratified v1.0.0)
Specification: ✅ (13-section spec.md)
Clarification: ✅ (7 questions documented, answered)
Plan: ✅ (plan.md with phases, subagents)
Tasks: ✅ (tasks.md with acceptance criteria)
Analysis: ✅ (cross-artifact consistency check)
Implementation: ✅ (code traced to tasks/spec)
ADRs: ✅ (5 ADRs for major decisions)
PHRs: ✅ (9 PHRs in history/prompts/)
→ BONUS QUALIFYING (1.5x multiplier) ✅
```

---

## Validation Output Template

Each validation produces:

```json
{
  "feature_name": "[Name]",
  "category": "[skill|component|workflow|content|auth|translation|artifact]",
  "submission_date": "[YYYY-MM-DD]",

  "is_bonus_qualifying": true|false,

  "bonus_criteria_checked": [
    {
      "criterion_name": "Reusable Intelligence",
      "status": "✅ PASS" | "❌ FAIL" | "⚠️ PARTIAL",
      "details": "[Explanation of what was checked]",
      "evidence": "[What evidence supports this status]",
      "confidence": "high|medium|low"
    }
  ],

  "bonus_multipliers": {
    "reusable_intelligence": 1.0,  // 1.0-2.0x
    "personalization": 1.0,        // 1.0-1.6x
    "urdu_translation": 1.0,       // 1.0-1.7x
    "spec_kit_plus": 1.0,          // 1.0-1.5x
    "combined_multiplier": 1.0     // PRODUCT of all multipliers
  },

  "total_estimated_bonus_score": 0,  // Project score × combined_multiplier

  "recommendations": [
    "[Improvement 1]",
    "[Improvement 2]"
  ],

  "validator_notes": "[Additional context or observations]"
}
```

---

## Usage Examples

### Example 1: Validating ChapterWriter Skill
```
Input:
  feature_description: "Claude Code agent skill that generates complete MDX chapters with learning outcomes, code examples, quizzes"
  feature_category: skill
  implementation_details:
    reusability_score: 9
    documentation_level: comprehensive
    testing_coverage: end-to-end

Output:
  is_bonus_qualifying: true
  bonus_criteria_met: ["Reusable Intelligence", "Implementation Quality"]
  bonus_multiplier: 1.7x (5+ skills with automation)
  recommendations: ["Used on all 12 chapters", "Documented with examples"]
```

### Example 2: Validating Urdu Translation Feature
```
Input:
  feature_description: "75% of chapters translated to Urdu with technical terms preserved, per-chapter toggle button"
  feature_category: translation
  implementation_details:
    reusability_score: 8
    documentation_level: comprehensive
    testing_coverage: integration

Output:
  is_bonus_qualifying: true
  bonus_criteria_met: ["Urdu Translation (75% coverage)"]
  bonus_multiplier: 1.5x
  recommendations: ["Complete remaining 25%", "Add glossary"]
```

### Example 3: Validating Personalization Feature
```
Input:
  feature_description: "User signup with background collection, difficulty toggle, progress tracking, preference persistence"
  feature_category: auth
  implementation_details:
    reusability_score: 7
    documentation_level: comprehensive
    testing_coverage: end-to-end

Output:
  is_bonus_qualifying: true
  bonus_criteria_met: ["User Personalization (5+ features)", "Auth Implementation"]
  bonus_multiplier: 1.4x
  recommendations: ["Add learning path recommendations"]
```

---

## Integration

Part of @Reviewer subagent workflow. Run at:
1. Feature completion (mid-project validation)
2. Before final submission (comprehensive audit)
3. On-demand during development (quick checks)

Supports hackathon goal: maximize bonus points via systematic validation of high-value features.

## Success Metrics
- ✅ Validation accuracy: 95%+ (matches actual submission rubric)
- ✅ Time to validate: < 5 minutes per feature
- ✅ Clear pass/fail criteria with evidence
- ✅ Actionable recommendations for improvement

